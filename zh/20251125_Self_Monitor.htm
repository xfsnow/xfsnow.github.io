<!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><title>雪峰博客</title><meta name="description" content="分享AI和云计算技术的最新动态与实践经验，以及其它有趣的话题。"><meta name="keywords" content="AI, GitHub Copilot, Azure云, 云计算, 前端技术, 后端技术, Web开发, 软件工程"><link rel="stylesheet" href="/assets/css/style.min.css"><link rel="stylesheet" href="https://site-assets.fontawesome.com/releases/v7.1.0/css/all.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/default.min.css"></head><body><nav class="navbar"><div class="nav-container"><div class="nav-logo"><h2><i class="fas fa-snowflake"></i> Snowpeak</h2></div><div class="nav-menu"><a href="/" class="nav-link">首页</a><a href="/zh/page_1.htm" class="nav-link">文章</a><a href="/#tools" class="nav-link">工具</a><a href="/zh/about.htm" class="nav-link">关于</a><a href="/en/" class="nav-link lang-switch"><i class="fas fa-globe"></i> English</a></div><div class="nav-toggle" id="mobile-menu"><span class="bar"></span><span class="bar"></span><span class="bar"></span></div></div></nav><header class="article-header"><div class="container"><h1>无托管服务的全球云资源监控系统</h1><div class="article-meta"><span><i class="fas fa-calendar"></i> 发布时间: 2025-11-26 18:20:00</span><span><i class="fas fa-clock"></i> 阅读约需: 6 分钟 </span><span><i class="fas fa-tag"></i> 分类: 云计算</span></div></div></header><main class="article-container"><p>像 AWS 这样的服务商，如 AWS、Azure、Google Cloud 等，都提供了丰富的资源监控服务，但这些服务通常成本相对较高，且各云平台上的监控服务各不兼容。使用多云部署的用户也不想锁定到某一家服务商，基于云平台的 IaaS 服务使用主流开源软件搭建一套监控系统，是一种运维最佳实践。</p><p>此文以 AWS 云为示例，介绍如何使用无托管服务搭建一套全球资源监控系统。其它云平台类似。</p><p><strong>核心目标</strong>：监控AWS基础资源健康、自搭建数字系统运行状态，无托管服务依赖，全球高可用，99.99%可用性。</p><h2>一、核心设计边界与原则</h2><h3>1. 监控对象（明确聚焦）</h3><ul><li><strong>AWS基础资源</strong>：EC2、VPC（子网/路由表/安全组）、ELB（NLB/ALB）、S3（存储桶）、EBS、Route53等；</li><li><strong>自搭建数字系统</strong>：K8s集群（Master/Worker节点）、中间件（Kafka/EMQ X）、数据库（MySQL/InfluxDB）、应用服务（微服务容器）等；</li><li><strong>核心监控维度</strong>：资源使用率（CPU/内存/磁盘/网络）、服务可用性（存活状态/响应延迟）、故障事件（重启/崩溃/连接失败）、性能指标（QPS/吞吐量/查询延迟）。</li></ul><h3>2. 设计原则</h3><ul><li>无托管依赖：仅使用AWS基础资源（EC2、VPC、ELB、S3、ASG、IAM、KMS），自搭建所有监控组件；</li><li>高可用架构：多区域（≥3个）+ 单区域多AZ（≥2个）部署，无单点故障；</li><li>全球覆盖：跨区域指标聚合、就近访问监控面板，全球延迟&lt;1秒；</li><li>轻量化采集：最小化采集端资源消耗，避免监控本身影响业务系统；</li><li>快速告警：故障检测→告警触发≤30秒，支持多级告警路由。</li></ul><h2>二、整体架构分层设计</h2><h3>架构总览</h3> <pre><code>监控对象（AWS资源+自搭系统）→ 指标采集层（自部署采集器）→ 传输转发层（自搭Kafka）→ 存储分析层（Prometheus+Thanos）→ 可视化告警层（Grafana+Alertmanager）
                                  ↓                                      ↓
                          跨区域数据同步（Kafka MirrorMaker）        容灾备份层（S3+跨区域复制）
</code></pre> <h2>三、各层详细设计（无托管服务依赖）</h2><h3>（一）指标采集层：全维度数据采集，无死角覆盖</h3><h4>核心目标：轻量化、多源采集，适配AWS资源+自搭系统</h4><ol><li><p><strong>技术选型（纯自部署）</strong>： - 资源指标采集：Node Exporter（系统级）、AWS CLI自定义脚本（AWS资源）、cAdvisor（容器级）； - 服务指标采集：Blackbox Exporter（端口/HTTP存活）、JMX Exporter（中间件）、自定义Exporter（数据库/应用）； - 采集器部署：所有采集器以Docker容器形式运行在EC2或K8s节点上，无托管采集服务依赖。</p></li><li><p><strong>分场景采集方案</strong>：</p></li></ol><table><thead><tr><th>监控对象</th><th>采集工具/方式</th><th>核心采集指标</th></tr></thead><tbody><tr><td>AWS EC2/EBS</td><td>Node Exporter + AWS CLI脚本（定时调用AWS API）</td><td>CPU使用率、内存使用率、磁盘IO、网络吞吐量、EBS读写延迟、实例状态（运行/停止/重启）</td></tr><tr><td>AWS VPC/安全组</td><td>自定义Shell脚本（定时校验路由表可达性、安全组规则有效性）+ Route53健康检查</td><td>子网可用IP数、路由表关联状态、安全组端口开放状态、VPC流量丢弃率</td></tr><tr><td>AWS ELB/S3</td><td>AWS CLI脚本（定时查询ELB健康状态、S3存储量/请求成功率）</td><td>ELB后端健康实例数、请求量、响应延迟、S3存储使用率、PUT/GET成功率</td></tr><tr><td>自搭K8s集群</td><td>cAdvisor + Kube-state-metrics（自部署）</td><td>Pod/Node资源使用率、Pod重启次数、Deployment副本就绪率、Node就绪状态</td></tr><tr><td>中间件（Kafka/MySQL）</td><td>JMX Exporter（Kafka）+ 自定义SQL脚本（MySQL）</td><td>Kafka分区健康、Topic堆积量、MySQL连接数、查询延迟、主从同步延迟</td></tr><tr><td>应用服务</td><td>自定义Exporter（埋点暴露/日志解析）</td><td>接口响应时间、错误率、QPS、线程池状态</td></tr></tbody></table><ol start="3"><li><strong>采集优化</strong>： - 采集频率：核心指标（CPU/内存/存活状态）10秒/次，非核心指标（存储使用率/S3状态）60秒/次； - 轻量化：采集器容器限制CPU≤0.2vCPU、内存≤256MB，避免占用业务资源； - 容错：采集失败时本地缓存指标（保留5分钟），恢复后批量上报，避免数据丢失。</li></ol><h3>（二）传输转发层：高可靠、低延迟的指标流转</h3><h4>核心目标：削峰填谷、跨区域传输、避免指标丢失</h4><ol><li><p><strong>技术选型</strong>：自搭建Kafka集群（替代托管消息服务）+ Kafka MirrorMaker（跨区域同步）；</p></li><li><p><strong>部署架构</strong>： - 单区域内：3个AZ各部署1台EC2（i3.large，本地SSD）作为Kafka Broker，1台EC2作为ZooKeeper（3节点集群），Topic设置3副本（跨AZ）； - 跨区域同步：部署Kafka MirrorMaker 2.0，将各区域Kafka的指标Topic同步至其他区域，确保跨区域数据一致性； - Topic设计：按指标类型拆分，如<code>monitor/aws/ec2</code>、<code>monitor/system/k8s</code>、<code>monitor/middleware/kafka</code>，每个Topic分区数=区域内Broker数；</p></li><li><p><strong>关键保障</strong>： - 可靠性：Kafka Topic数据保留期24小时，支持指标重放；启用ACK=all，确保数据写入所有副本后才算成功； - 削峰：应对指标采集峰值（如系统重启时批量上报），Kafka缓冲队列避免后端存储过载； - 加密传输：Kafka节点间通信启用TLS 1.3，采集器→Kafka传输通过SASL认证+TLS加密。</p></li></ol><h3>（三）存储分析层：时序数据存储+跨区域聚合</h3><h4>核心目标：高吞吐写入、低延迟查询、长期存储、全球数据聚合</h4><ol><li><p><strong>技术选型</strong>：自搭建Prometheus集群（实时指标）+ Thanos（长期存储+跨区域聚合）+ S3（冷数据归档）；</p></li><li><p><strong>部署架构</strong>： - 区域级Prometheus：3个核心区域（美东、欧西、亚太）各部署1套Prometheus高可用集群（2个Server节点+共享存储），通过Kafka Adapter消费Kafka指标并写入Prometheus；</p><ul><li>存储配置：本地SSD存储热数据（近7天），写入吞吐量支持10万指标/秒；</li><li>高可用：2个Prometheus Server配置相同采集规则，数据通过Thanos Sidecar同步，避免单点故障；</li><li>Thanos集群（跨区域聚合）：</li><li>Thanos Query：每个区域部署1台EC2（m5.large），接收Grafana查询请求，聚合本区域+其他区域的Prometheus数据；</li><li>Thanos Store Gateway：部署在S3访问优化区域，对接S3冷数据存储（7天前指标），支持历史数据查询；</li><li>Thanos Compactor：定期压缩S3中的历史指标，降低存储成本；</li><li>长期存储：Prometheus热数据7天后通过Thanos Uploader迁移至S3，S3开启跨区域复制（同步至2个备用区域），数据保留90天（可配置）。</li></ul></li><li><p><strong>查询优化</strong>： - 指标分片：按区域+指标类型分片存储，查询时仅路由至目标分片； - 缓存策略：Thanos Query启用本地缓存（缓存热点查询结果5分钟），降低跨区域查询延迟； - 索引优化：Prometheus启用倒排索引，支持按资源ID（如EC2实例ID、K8s Pod名称）快速过滤指标。</p></li></ol><h3>（四）可视化告警层：全球统一视图+实时告警</h3><h4>核心目标：直观展示、快速告警、故障定位</h4><ol><li><p><strong>技术选型</strong>：自搭建Grafana（可视化）+ Alertmanager（告警）+ 自定义告警路由服务；</p></li><li><p><strong>部署架构</strong>： - Grafana集群：3个区域各部署1台EC2（t3.medium），通过NLB+Route53智能DNS实现全球就近访问；</p><ul><li>数据来源：对接所有区域的Thanos Query，支持“全球总览-区域详情-资源明细”三级仪表盘；</li><li>权限控制：启用LDAP认证（自搭建OpenLDAP集群），按角色（管理员/运维/开发）划分资源访问权限；</li><li>Alertmanager集群：每个区域部署1台EC2（t3.small），与Prometheus集群关联，支持告警分组、静默、抑制；</li><li>告警路由：自开发告警转发服务（部署在K8s），支持将告警推送至邮件、协同办公系统及工单系统，按故障级别（P0-P3）路由至不同负责人。</li></ul></li><li><p><strong>核心功能适配</strong>： - 可视化仪表盘：</p><ul><li>全局总览：各区域AWS资源可用率、系统服务健康度、TOP5告警类型；</li><li>资源详情：EC2/ELB/S3的实时指标曲线（CPU/内存/流量）、异常指标标记；</li><li>故障排查：关联指标+日志（对接自搭建ELK集群），支持按时间范围回溯故障前后数据；</li><li>告警规则：</li><li>P0（致命）：区域级服务崩溃（如Kafka集群不可用）、核心EC2实例离线&gt;30秒；</li><li>P1（严重）：资源使用率超阈值（CPU&gt;90%持续5分钟）、数据库连接数超上限；</li><li>P2（一般）：非核心服务响应延迟&gt;1秒、S3存储使用率超80%；</li><li>P3（提示）：资源配置即将到期、非核心指标波动。</li></ul></li></ol><h3>（五）容灾与高可用层：故障无感知切换</h3><h4>核心目标：单区域故障时监控不中断、数据不丢失</h4><ol><li><p><strong>区域级故障转移</strong>： - Route53健康检查：监控各区域Grafana、Thanos Query的可用性，当某区域故障时，自动将用户请求转发至就近正常区域； - 数据冗余：Kafka跨区域同步确保指标不依赖单区域，Prometheus热数据跨AZ存储，S3冷数据跨区域备份；</p></li><li><p><strong>服务级故障自愈</strong>： - 采集器：部署在ASG中，EC2节点故障时自动重启采集器容器； - Kafka/Prometheus：通过自写监控脚本（部署在EC2）检测服务状态，故障时自动重启，重启失败则触发ASG扩容新节点； - 数据库（OpenLDAP/MySQL）：主从复制+Keepalived自动切换，故障切换时间&lt;10秒。</p></li></ol><h2>四、核心监控场景落地</h2><h3>1. AWS基础资源健康监控</h3><ul><li>EC2故障检测：Node Exporter采集实例状态，Prometheus规则判断“实例状态≠running”或“CPU使用率=0且内存使用率&lt;10%”，触发P1告警；</li><li>VPC网络异常：自定义脚本定时校验子网路由可达性，若连续3次失败，告警并推送路由表配置快照；</li><li>S3可用性监控：AWS CLI脚本定时执行S3 Put/GET操作，请求成功率&lt;99.99%或延迟&gt;500ms，触发P2告警。</li></ul><h3>2. 自搭建系统运行监控</h3><ul><li>K8s集群健康：Kube-state-metrics采集Pod重启次数，10分钟内重启&gt;3次触发P1告警；Node就绪状态异常&gt;1分钟，自动触发ASG扩容新节点；</li><li>Kafka故障监控：JMX Exporter采集分区副本同步状态，若“ISR副本数&lt;2”或“Topic堆积量&gt;10万条”，触发P0/P1告警；</li><li>应用服务监控：自定义Exporter采集接口错误率，5分钟内错误率&gt;1%触发P2告警，错误率&gt;5%触发P1告警并自动调用应用重启接口。</li></ul><h3>3. 故障根因定位</h3><ul><li>指标关联：Grafana支持“资源指标+服务指标”联动查询（如EC2 CPU 100% → 关联K8s Pod资源使用率 → 定位过载Pod）；</li><li>日志联动：自搭建ELK集群（EC2部署）收集系统/应用日志，Grafana嵌入ELK查询入口，可通过资源ID/时间范围关联指标与日志，快速定位故障原因。</li></ul><h2>五、安全与合规设计</h2><ol><li><strong>数据安全</strong>：</li></ol><ul><li>传输加密：所有链路（采集器→Kafka、Kafka→Prometheus、Grafana→Thanos）均启用TLS 1.3；</li><li>存储加密：EC2磁盘EBS加密、S3存储桶启用SSE-KMS加密、Prometheus/MySQL数据文件加密；</li><li>权限控制：基于IAM角色限制EC2访问AWS资源（如仅允许采集器EC2调用EC2/S3 API），Grafana/LDAP按角色隔离监控数据访问权限。</li></ul><ol start="2"><li><strong>合规适配</strong>：</li></ol><ul><li>日志审计：所有监控操作（告警触发、权限变更、仪表盘修改）记录日志，存储至S3保留1年，符合GDPR/CCPA审计要求；</li><li>数据脱敏：监控指标中隐藏敏感信息（如EC2实例密码、数据库连接串），仅保留资源ID、指标数值等必要信息。</li></ul><h2>六、运维自动化设计（无托管运维服务）</h2><ol><li><strong>基础设施编排</strong>：</li></ol><ul><li>Terraform IaC：编写模块化代码，批量创建EC2、VPC、ELB、Route53等基础资源，以及Kafka、Prometheus、Grafana等自搭建组件的部署配置；</li><li>环境一致性：通过Terraform工作区区分dev/test/prod，状态文件存储在S3+DynamoDB锁，避免配置冲突。</li></ul><ol start="2"><li><strong>服务自动化运维</strong>：</li></ol><ul><li>自写Shell/Python脚本：监控采集器、Kafka、Prometheus的运行状态，异常时自动重启服务，重启失败则触发ASG扩容；</li><li>配置自动同步：通过Git+Ansible同步所有监控组件的配置文件（如Prometheus规则、Grafana仪表盘），修改后自动下发至所有节点；</li><li>版本升级：采用蓝绿部署模式升级监控组件（如Grafana/Prometheus），确保升级过程中监控不中断。</li></ul><h2>七、核心指标保障</h2><table><thead><tr><th>指标类型</th><th>目标值</th><th>实现手段</th></tr></thead><tbody><tr><td>系统可用性</td><td>99.99%（年故障&lt;53分钟）</td><td>多区域+多AZ部署、自动故障转移、服务多副本</td></tr><tr><td>指标采集延迟</td><td>&lt;30秒</td><td>轻量化采集器、Kafka低延迟传输</td></tr><tr><td>告警触发延迟</td><td>&lt;30秒</td><td>Prometheus实时规则评估、Alertmanager秒级转发</td></tr><tr><td>跨区域查询延迟</td><td>&lt;1秒</td><td>Thanos就近聚合、缓存优化</td></tr><tr><td>数据存储期限</td><td>热数据7天、冷数据90天</td><td>Prometheus+S3分层存储</td></tr></tbody></table><h2>总结</h2><p>该架构完全基于AWS基础资源自搭建，无任何托管服务依赖，通过“全维度采集→高可靠传输→分层存储→全球聚合→实时告警”的闭环设计，实现AWS基础资源与自搭建数字系统的统一监控。多区域+多AZ部署保障99.99%可用性，跨区域数据同步与就近访问适配全球业务，轻量化采集与优化存储平衡性能与成本，完全满足“系统+云资源”的全球监控需求，同时适配外资企业的安全合规要求。</p></main><footer class="footer"><div class="container"><div class="footer-content"><div class="footer-section"><h3><i class="fas fa-snowflake"></i> Snowpeak</h3><p>分享AI和云计算技术的最新动态与实践经验，以及其它有趣的话题。</p><div class="social-links"><div class="social-platforms"><a href="https://github.com/xfsnow" target="_blank" class="social-link"><i class="fab fa-github"></i></a><a href="https://snowpeak.blog.csdn.net/" target="_blank" class="social-link"><i class="fas fa-blog"></i></a><a href="https://space.bilibili.com/701839928" target="_blank" class="social-link"><i class="fab fa-bilibili"></i></a><a href="https://www.linkedin.com/in/snowpeak" target="_blank" class="social-link"><i class="fab fa-linkedin"></i></a></div><div class="wechat-section"><div class="wechat-info"><span class="wechat-label">微信公众号</span><span class="wechat-name">技术温暖生活</span></div><img src="/assets/img/techwarm.jpg" alt="技术温暖生活" class="wechat-qr"></div></div></div><div class="footer-section"><h4>快速链接</h4><ul><li><a href="/#articles">文章</a></li><li><a href="/#tools">工具</a></li><li><a href="https://docs.github.com/en/pages" target="_blank">GitHub Pages</a></li></ul></div><div class="footer-section"><h4>技术栈</h4><ul><li>Python</li><li>GitHub Copilot</li><li>Claude Sonnet 4</li><li>HTML/CSS/JS</li><li>响应式设计</li></ul></div></div><div class="footer-bottom"><p>Copyright &copy; 2013-<script>document.write((new Date()).getFullYear());</script> 雪峰博客。运行在 GitHub Pages 上。 <a href="https://beian.miit.gov.cn" target="_blank" class="icp_beian">京ICP备2021007720号</a><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010502052523" target="_blank" class="gongan_beian">京公网安备11010502052523号</a></p></div></div></footer><script src="/zh/index.js"></script><script src="/assets/js/blog.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script><script>hljs.highlightAll(); if (window.location.hostname === 'www.snowpeak.org') { const script = document.createElement('script'); script.defer = true; script.src = 'https://static.cloudflareinsights.com/beacon.min.js'; script.dataset.cfBeacon = JSON.stringify({ "token": "4c2c021185e64942857a36d116eb4711" }); document.head.appendChild(script); } </script></body></html>